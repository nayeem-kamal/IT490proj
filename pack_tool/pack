#!/usr/bin/python3
'''
Pack tool for making and sending
packages to deployment server

package naming convention: samplepak-1.0
'''
import fire
import socket
import os
import yaml
import sys
import subprocess
import tarfile
import shutil
import datetime
import glob

deploy_host = 'deploy'
deployment_server = f'{deploy_host}:/home/deploy/packages/incoming/'
config_path = os.environ['HOME'] + '/.config/packtool/config.yaml'
pkg_extension = '.tar.gz'
show_last_logs = 2

def get_config():
    '''grabs configuration info'''

    with open(config_path, 'r') as file:
        config_yaml = yaml.safe_load(file)

    return config_yaml


def emit_log(yaml_dict, make=False, install=False):
    '''Takes in dict of pkg information, writes to log file'''

    tagline = ''
    if make:
        tagline = 'Package Created'
    elif install:
        tagline = 'Package Installed'

    time = datetime.datetime.now().ctime()
    config_yaml = get_config()

    with open(config_yaml['log_path'], 'a') as file:
        file.write('*-\n')
        file.write(tagline + '\n')
        file.write(time + '\n')
        yaml.dump(yaml_dict, file, sort_keys=False)


def get_file_paths(args, root):
    '''gets full paths for given files'''

    # directory traversal to establish full paths for files
    installpaths = {}
    duplicate_check = {}
    for dir_name, sub_dir_list, file_list in os.walk(root):
        if '.git' not in dir_name:
            if 'pycache' not in dir_name:
                for fname in file_list:
                    if fname in args:
                        # dir slash issue correction due to os.walk subdirs
                        if '/' not in dir_name[-1]:
                            directory_name = dir_name+'/'
                        else:
                            directory_name = dir_name
                        # check for duplicate filenames spawning multiple paths
                        if fname not in installpaths:
                            installpaths[fname] = directory_name+fname
                        else:
                            if fname not in duplicate_check:
                                duplicate_check[fname] = [directory_name+fname]
                                duplicate_check[fname].append(installpaths[fname])
                            else:
                                duplicate_check[fname].append(directory_name+fname)

    # check if all given filenames have found their paths
    if len(installpaths) != len(args):
        sys.exit("Not all files found, check names")

    # duplicate checking
    if len(duplicate_check) >= 1:
        print('These paths were found with duplicate file names:')
        for key in duplicate_check:
            print(f'{key}:')
            for path in duplicate_check[key]:
                print(f'\t{duplicate_check[key].index(path)}: {path}')
            correct_path = 1000
            while correct_path not in range(0, len(duplicate_check[key])):
                correct_path = int(input('Choose correct path by number: '))
            installpaths[key] = duplicate_check[key][correct_path]

    return installpaths


def make(pkgname, *args):
    '''
    Creates and sends package. Format: 'pack make samplepak-1.2 file1 file2 file3'
    '''

    # ensure proper package name convention and parameter order (kindof)
    try:
        pkgversion = float(pkgname.split('-')[1])
    except Exception:
        sys.exit('Error: Double check your order or package naming convention')

    # get config yaml info and config path
    config_yaml = get_config()

    # user needs to set the root of their working project folder before proceeding
    if 'root_path' not in config_yaml:
        sys.exit('Run "pack setroot <full path>" to set the root of your project file directory then rerun')

    # get the full paths for the given files
    installpaths = get_file_paths(args, config_yaml['root_path'])

    # establish the yaml structure for the package
    yaml_dict = {'pkgid': '', 'pkgname': pkgname, 'pkgversion': str(pkgversion),
            'sourcenode': socket.gethostname(), 'pkgstatus': 'new',
            'install': installpaths}

    # write pkg.yaml to tmp for packaging
    with open(config_yaml['tmp_path'] + 'pkg.yaml', 'w') as file:
        yaml.dump(yaml_dict, file, sort_keys=False)

    # copy pkg files to tmp for packaging
    for fname in installpaths:
        shutil.copyfile(installpaths[fname], config_yaml['tmp_path']+fname)

    # tar.gz files in tmp, changing working directory to tmp
    subprocess.run(f'tar -czf {pkgname}{pkg_extension} *', cwd=config_yaml['tmp_path'], shell=True)

    # send pkg.tar.gz to deployment server
    #subprocess.run(['scp', config_yaml['tmp_path']+pkgname+pkg_extension, deployment_server])

    # remove all files in tmp, assuming ubuntu gio for now, not using rm * for safety
    #subprocess.run('gio trash *', cwd=config_yaml['tmp_path'], shell=True)
    #tmp_file_list = glob.glob(config_yaml['tmp_path']+"*")
    #for file in tmp_file_list:
    #    os.remove(file)

    # add package details to log
    emit_log(yaml_dict, make=True)


def unpack_yaml(pkg_path, tmp_path):
    '''takes in src path of tar.gz, writes pkg yaml to tmp, returns yaml'''

    # reading pkg.yaml inside package.tar.gz, stores to tmp dir (was easier this way)
    command = f"tar -xf {pkg_path} -C {tmp_path} pkg.yaml"
    os.system(command)
    pkg_yaml_path = tmp_path + 'pkg.yaml'
    with open(pkg_yaml_path, 'r') as file:
        pkg_yaml = yaml.safe_load(file)

    # clean file from tmp
    os.remove(pkg_yaml_path)

    return pkg_yaml


def unpack_tar_gz(pkg_path, tmp_path):
    '''unpacks tar to tmp to read pkg.yaml and install files'''

    # unpack tar.gx to tmp
    command = f"tar -xf {pkg_path} -C {tmp_path}"
    os.system(command)
    pkg_yaml_path = tmp_path + 'pkg.yaml'
    with open(pkg_yaml_path, 'r') as file:
        pkg_yaml = yaml.safe_load(file)

    return pkg_yaml


def install(pkgname):
    '''
    Installs next package.
    Format:
        'pack install pkgname'
    '''
    ext = '.tar.gz'

    if ext not in pkgname:
        pkgname = pkgname+ext

    config_yaml = get_config()

    # should only be one file in directory
    file = os.listdir(config_yaml['new_pkg_path'])
    if not file:
        print('No packages to install.')
        return
    else:
        pkg_yaml = unpack_tar_gz(config_yaml['new_pkg_path']+file[0], config_yaml['tmp_path'])

    # grab install paths
    path_dict = pkg_yaml['install']

    # TO DO...
    # make a pkg.yaml that outlines rollback
    # keeping track of files that were overwritten
    # but also keeping track of newly created files that should be
    # removed on a rollback.. so
    # if file exists, backup, if not, take note in yaml that it should be removed if rolledback
    # rollback yaml slightly different structure

    # once backup files and yaml are in backup, tar.gz them, then delete loose files
    #


    # if existing, copy file to backup directory
    for key in path_dict:
        if os.path.isfile(path_dict[key]):
            shutil.copy(path_dict[key], config_yaml['backup_path'])

    # create paths in the case that new folders were created
    for key in path_dict:
        # slice off file at the end of file path, create path if nonexistent
        path = path_dict[key][:path_dict[key].index(key)]
        if not os.path.isdir(path):
            command = f'mkdir -p {path}'
            os.system(command)

    # copy files to given paths to install
    for key in path_dict:
        shutil.copy(config_yaml['tmp_path']+key, path_dict[key])

    emit_log(pkg_yaml, install=True)

    # mv package from new packages after install
    #
def packages():
    '''
    Lists next package ready to be installed.
    Format:
        'pack packages'
    '''
    config_yaml = get_config()

    # should only be one file in directory
    file = os.listdir(config_yaml['new_pkg_path'])
    if not file:
        print('No packages to install.')
        return
    else:
        pkg_yaml = unpack_yaml(config_yaml['new_pkg_path']+file[0], config_yaml['tmp_path'])

    t = os.path.getmtime(config_yaml['new_pkg_path']+file[0])
    date = datetime.datetime.fromtimestamp(t).ctime()
    
    print('*********************')
    print('1 Package to install:')
    print('*********************')
    print(f'***Filename: {file[0]}***')
    print(f'***Uploaded: {date}***')
    for key, value in pkg_yaml.items():
        print(f'\t{key}: {value}')


def setroot(root_path):
    '''
    Sets the root of the working project folder.
    Format:
        'pack setroot /home/Desktop/repo_name/'
    '''

    # validation attempt for ending slash,
    # comes into affect during directory traversal
    if '/' not in root_path[-1]:
        root_path = root_path + '/'

    # grab current config contents
    config_yaml = get_config()

    # puts root_path in if nonexistent, overwrites if existent
    config_yaml['root_path'] = root_path

    # dumps pack out to config file
    with open(config_path, 'w') as file:
        yaml.dump(config_yaml, file, sort_keys=False)


def log():
    '''Prints out info for last created packages. Format: 'pack log' '''

    config = get_config()
    if 'log_path' not in config:
        sys.exit("Hm, not seeing a log path inside your config.")

    with open(config['log_path'], 'r') as file:
        lines = file.readlines()

    # traverses list backwards to print logs last to first
    # only shows specified count
    # default show_last_logs = last 2 sent packages
    idx = -1
    count = 0
    last_delim = -1
    logcount = 0
    while count < len(lines):
        if '*-' in lines[idx]:
            subcount = idx
            while subcount <= last_delim:
                print(lines[subcount], end='')
                subcount = subcount + 1
            logcount = logcount + 1
            if logcount == show_last_logs:
                break
            last_delim = idx
        idx = idx - 1
        count = count + 1


def help():
    pass


if __name__ == '__main__':
    fire.Fire({
        'make': make,
        'install': install,
        'packages': packages,
        'setroot': setroot,
        'log': log,
    })
