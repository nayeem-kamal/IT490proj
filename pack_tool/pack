#!/usr/bin/python3
'''
Pack tool for making and sending
packages to deployment server

package naming convention: samplepak-1.0
'''
from paramiko import SSHClient
from scp import SCPClient
import fire
import socket
import os
import yaml
import sys
import subprocess
import tarfile
import shutil
import datetime
import glob

test_ip = '192.168.100.4'
deployment_ip = '192.168.194.69'
deployment_user = 'deploy'
deployment_pw = 'password'
deployment_remote_path = '/home/deploy/packages/incoming/'
#deploy_host = 'deploy'
#deployment_server = f'{deploy_host}:/home/deploy/packages/incoming/'
config_path = os.environ['HOME'] + '/.config/packtool/config.yaml'
pkg_extension = '.tar.gz'
show_last_logs = 1


def get_config():
    '''grabs configuration info'''

    with open(config_path, 'r') as file:
        config_yaml = yaml.safe_load(file)

    return config_yaml


def emit_log(yaml_dict, make=False, install=False, approved=False):
    '''Takes in dict of pkg information, writes to log file'''

    tagline = ''
    if make:
        tagline = 'Package Created'
    elif install:
        tagline = 'Package Installed'
    elif approved:
        tagline = 'Package Approved'

    time = datetime.datetime.now().ctime()
    config_yaml = get_config()

    with open(config_yaml['log_path'], 'a') as file:
        file.write('*-\n')
        file.write(tagline + '\n')
        file.write(time + '\n')
        yaml.dump(yaml_dict, file, sort_keys=False)


def get_file_paths(args, root):
    '''gets full paths for given files'''

    # directory traversal to establish full paths for files
    installpaths = {}
    duplicate_check = {}
    for dir_name, sub_dir_list, file_list in os.walk(root):
        if '.git' not in dir_name:
            if 'pycache' not in dir_name:
                for fname in file_list:
                    if fname in args:
                        # dir slash issue correction due to os.walk subdirs
                        if '/' not in dir_name[-1]:
                            directory_name = dir_name+'/'
                        else:
                            directory_name = dir_name
                        # check for duplicate filenames spawning multiple paths
                        if fname not in installpaths:
                            installpaths[fname] = directory_name+fname
                        else:
                            if fname not in duplicate_check:
                                duplicate_check[fname] = [directory_name+fname]
                                duplicate_check[fname].append(installpaths[fname])
                            else:
                                duplicate_check[fname].append(directory_name+fname)

    # check if all given filenames have found their paths
    if len(installpaths) != len(args):
        sys.exit("Not all files found, check names")

    # duplicate checking
    if len(duplicate_check) >= 1:
        print('These paths were found with duplicate file names:')
        for key in duplicate_check:
            print(f'{key}:')
            for path in duplicate_check[key]:
                print(f'\t{duplicate_check[key].index(path)}: {path}')
            correct_path = 1000
            while correct_path not in range(0, len(duplicate_check[key])):
                correct_path = int(input('Choose correct path by number: '))
            installpaths[key] = duplicate_check[key][correct_path]

    return installpaths


def use_scp(full_pkg_path):
    '''makes ssh connection, sends package scp'''

    ssh = SSHClient()
    ssh.load_system_host_keys()
    ssh.connect(hostname=test_ip, username=deployment_user, password=deployment_pw, port=22)
    scp = SCPClient(ssh.get_transport())

    scp.put(full_pkg_path, deployment_remote_path)

    scp.close()
    ssh.close()

    return True


def no_nothing():
    '''do nothing for now'''
    pass


def make(pkgname, *args):
    '''
    Creates and sends package. Format: 'pack make samplepak-1.2 file1 file2 file3'
    '''

    # ensure proper package name convention and parameter order (kindof)
    try:
        pkgversion = float(pkgname.split('-')[1])
    except Exception:
        sys.exit('Error: Double check your order or package naming convention')

    # get config yaml info and config path
    config_yaml = get_config()

    # user needs to set the root of their working project folder before proceeding
    if 'root_path' not in config_yaml:
        sys.exit('Run "pack setroot <full path>" to set the root of your project file directory then rerun')

    # get the full paths for the given files
    installpaths = get_file_paths(args, config_yaml['root_path'])

    # establish the yaml structure for the package
    yaml_dict = {'pkgid': '', 'pkgname': pkgname, 'pkgversion': str(pkgversion),
            'sourcenode': socket.gethostname(), 'pkgstatus': 'new',
            'install': installpaths}

    # write pkg.yaml to tmp for packaging
    with open(config_yaml['tmp_path'] + 'pkg.yaml', 'w') as file:
        yaml.dump(yaml_dict, file, sort_keys=False)

    # copy pkg files to tmp for packaging
    for fname in installpaths:
        shutil.copyfile(installpaths[fname], config_yaml['tmp_path']+fname)

    # tar.gz files in tmp, changing working directory to tmp
    subprocess.run(f'tar -czf {pkgname}{pkg_extension} *', cwd=config_yaml['tmp_path'], shell=True)

    # send pkg.tar.gz to deployment server
    scp_success = False
    try:
        scp_success = use_scp(config_yaml['tmp_path']+pkgname+pkg_extension)
    except Exception as e:
        #do_nothing()
        print(e)

    #subprocess.run(['scp', config_yaml['tmp_path']+pkgname+pkg_extension, deployment_server])

    # remove all files in tmp
    tmp_file_list = glob.glob(config_yaml['tmp_path']+"*")
    for file in tmp_file_list:
        os.remove(file)

    if scp_success:
        # add package details to log
        emit_log(yaml_dict, make=True)
        print('Package created and sent successfully.')
    else:
        print('Not currently connected to deployment server.')


def unpack_yaml(pkg_path, tmp_path):
    '''takes in src path of tar.gz, writes pkg yaml to tmp, returns yaml'''

    # reading pkg.yaml inside package.tar.gz, stores to tmp dir (was easier this way)
    command = f"tar -xf {pkg_path} -C {tmp_path} pkg.yaml"
    os.system(command)
    pkg_yaml_path = tmp_path + 'pkg.yaml'
    with open(pkg_yaml_path, 'r') as file:
        pkg_yaml = yaml.safe_load(file)

    # clean file from tmp
    os.remove(pkg_yaml_path)

    return pkg_yaml


def unpack_tar_gz(pkg_path, tmp_path):
    '''unpacks tar to tmp to read pkg.yaml and install files'''

    # unpack tar.gx to tmp
    command = f"tar -xf {pkg_path} -C {tmp_path}"
    os.system(command)
    pkg_yaml_path = tmp_path + 'pkg.yaml'
    with open(pkg_yaml_path, 'r') as file:
        pkg_yaml = yaml.safe_load(file)

    return pkg_yaml


def repack_tar_gz(pkg_yaml):
    '''
    rewrites pkg.yaml with updated pkgstatus
    repacks tar in tmp, mvs to outstanding_packages, deletes original package
    '''

    config_yaml = get_config()
    tmp_path = config_yaml['tmp_path']
    outstanding_path = config_yaml['outstanding_path']

    pkgname = pkg_yaml['pkgname']
    pkg_extension = '.tar.gz'
    pkg_yaml['pkgstatus'] = 'outstanding'

    with open(tmp_path + 'pkg.yaml', 'w') as file:
        yaml.dump(pkg_yaml, file, sort_keys=False)

    # create new tar.gz from tmp files, change working dir to tmp then execute command
    subprocess.run(f'tar -czf {pkgname}{pkg_extension} *', cwd=tmp_path, shell=True)

    # move tar.gz to outstanding_packages
    shutil.move(tmp_path+pkgname+pkg_extension, outstanding_path)

    # remove original tar.gz from new_packages
    os.remove(config_yaml['new_pkg_path']+pkgname+pkg_extension)


def pack_approval(outstanding_path, approval_name):
    '''
    tar.gz the current backup file from the last installation
    stored in tmp until backup dir is scrubbed
    '''
    # tar.gz the files in bak_tmp
    subprocess.run(f'tar -czf {approval_name} *', cwd=outstanding_path, shell=True)



def update_current_pkgid(new_pkgid):
    '''
    Sets currently installed package id for reference.
    '''

    # grab current config contents
    config_yaml = get_config()

    config_yaml['last_pkgid'] = config_yaml['current_pkgid']
    # puts root_path in if nonexistent, overwrites if existent
    config_yaml['current_pkgid'] = new_pkgid

    # dumps pack out to config file
    with open(config_path, 'w') as file:
        yaml.dump(config_yaml, file, sort_keys=False)


def get_pkgid_info():
    '''
    Gets current last_pkgid and current_pkgid information.
    returns: dict 
    '''

    # grab current config contents
    config_yaml = get_config()

    return {'last_pkgid': config_yaml['last_pkgid'],
            'current_pkgid': config_yaml['current_pkgid']
            }


def install(pkgname):
    '''
    Installs next package.
    Format:
        'pack install pkgname'
    '''

    if pkg_extension not in pkgname:
        pkgname = pkgname+pkg_extension

    config_yaml = get_config()

    # should only be one file in directory
    file = os.listdir(config_yaml['new_pkg_path'])
    if not file:
        print('No packages to install.')
        return
    elif pkgname not in file[0]:
        print('Check package name.')
        return
    else:
        pkg_yaml = unpack_tar_gz(config_yaml['new_pkg_path']+file[0], config_yaml['tmp_path'])

    response = ''
    answers = ['yes', 'no']
    while response not in answers:
        response = input(f'Install {pkg_yaml["pkgname"]} on QA {pkg_yaml["pkgsource"]} (yes/no)? ')
    # grab install paths from new pkg yaml
    path_dict = pkg_yaml['install']

    # to store package/state reconstruction information
    updated_files = {}
    new_files = {}
    new_dirs_and_files = {}
    # if existing, copy file to backup directory, take note in yaml
    # if not existing but parent directories exist, take note in yaml
    # if not existing and parent directories not existing, take note in yaml

    # dynamically make backup tmp while creating backup package
    base_path = config_path[:config_path.index('config.yaml')]
    bak_tmp = base_path+'bak_tmp/'
    os.mkdir(bak_tmp)

    for key in path_dict:
        if os.path.isfile(path_dict[key]):
            shutil.copy(path_dict[key], bak_tmp)
            updated_files[key] = path_dict[key]
        elif os.path.isdir(path_dict[key][:path_dict[key].index(key)]):
            new_files[key] = path_dict[key]
        else:
            new_dirs_and_files[key] = path_dict[key]

    rollback_dict = {
            'updated_files': updated_files,
            'new_files': new_files,
            'new_dirs_and_files': new_dirs_and_files
    }

    # create paths in the case that new folders were created
    for key in path_dict:
        # slice off file at the end of file path, create path if nonexistent
        path = path_dict[key][:path_dict[key].index(key)]
        if not os.path.isdir(path):
            command = f'mkdir -p {path}'
            os.system(command)

    # copy files to given paths to install
    for key in path_dict:
        shutil.copy(config_yaml['tmp_path']+key, path_dict[key])

    # get current last_pkgid and current_pkgid to store in rollback_dict
    rollback_dict['pkginfo'] = get_pkgid_info()

    # set currently installed pkgid in config file
    update_current_pkgid(pkg_yaml['pkgid'])

    # add install/rollback information to installed package yaml
    pkg_yaml['rollback'] = rollback_dict

    # create rollback dir in tmp to store rollback files
    # and to be packaged up as an add on to original installed pkg
    os.mkdir(config_yaml['tmp_path']+'rollback/')

    # mv backup files from bak_tmp to tmp/rollback/
    backup_file_list = glob.glob(bak_tmp+"*")
    for file in backup_file_list:
        shutil.move(file, config_yaml['tmp_path']+'rollback/')

    # repacks installed pkg with added rollback info and files, moves to outstanding dir
    repack_tar_gz(pkg_yaml)

    # rm files in rollback dir before deleting
    rollback_file_list = glob.glob(config_yaml['tmp_path']+'rollback/*')
    for file in rollback_file_list:
        os.remove(file)
    # rm rollback dir in tmp before scrubbing tmp
    os.rmdir(config_yaml['tmp_path']+'rollback/')

    # removes all loose files in tmp dir (from the installed pkg)
    tmp_file_list = glob.glob(config_yaml['tmp_path']+"*")
    for file in tmp_file_list:
        os.remove(file)

    # dump rollback yaml to file in bak_tmp
    #with open(bak_tmp+'rollback.yaml', 'w') as file:
    #    yaml.dump(rollback_dict, file, sort_keys=False)

    # packs up backup files and rollback.yaml in bak_tmp
    # mvs the tar.gz to backups, embeds pkg installed name into backups name
    #pack_backup(pkg_yaml['pkgname'], bak_tmp)

    # removes all loose files in bak_tmp
    #bak_tmp_file_list = glob.glob(bak_tmp+"*")
    #for file in bak_tmp_file_list:
    #    os.remove(file)

    # removes the bak_tmp directory
    os.rmdir(bak_tmp)

    #pkg_yaml['details'] = rollback_dict
    emit_log(pkg_yaml, install=True)

    print('Package installed successfully. Check log for details.')


def packages():
    '''
    Lists next package ready to be installed.
    Format:
        'pack packages'
    '''
    config_yaml = get_config()

    # should only be one file in directory
    file = os.listdir(config_yaml['new_pkg_path'])
    if not file:
        print('No packages to install.')
        return
    else:
        if pkg_extension not in file[0]:
            print('Something funny with your package name..')
        else:
            pkg_yaml = unpack_yaml(config_yaml['new_pkg_path']+file[0], config_yaml['tmp_path'])

    t = os.path.getmtime(config_yaml['new_pkg_path']+file[0])
    date = datetime.datetime.fromtimestamp(t).ctime()

    print('*********************')
    print('1 Package to install:')
    print('*********************')
    print(f'***Filename: {file[0]}***')
    print(f'***Uploaded: {date}***')
    for key in pkg_yaml:
        if isinstance(pkg_yaml[key], dict):
            print(f'\t{key}:')
            for key2, value in pkg_yaml[key].items():
                print(f'\t  {key2}: {value}')
        else:
            print(f'\t{key}: {pkg_yaml[key]}')


def approve():
    '''
    approves current outstanding package
    sends approval to deployment server
    '''

    config_yaml = get_config()

    pkgname = os.listdir(config_yaml['outstanding_path'])[0]

    response = ''
    valid_answers = ['yes', 'no']
    while response not in valid_answers:
        response = input(f'Approve package {pkgname} (yes/no)? ')

    if response == 'no':
        return

    full_pkg_path = config_yaml['outstanding_path']+pkgname

    # unpack tar.gz from outstanding package to tmp, grab yaml
    pkg_yaml = unpack_tar_gz(full_pkg_path, config_yaml['tmp_path'])

    # change status to approved
    pkg_yaml['pkgstatus'] = 'approved'

    # writes pkg approval yaml to tmp dir
    with open(config_yaml['tmp_path']+'pkg.yaml', 'w') as file:
        yaml.dump(pkg_yaml, file, sort_keys=False)

    # .tar.gz approval package of items in tmp
    approval_name = pkg_yaml['pkgname']+'.appd.tar.gz'
    subprocess.run(f'tar -czf {approval_name} *', cwd=config_yaml['tmp_path'], shell=True)

    # attempt scp transfer
    scp_success = False
    try:
        scp_success = use_scp(config_yaml['tmp_path']+approval_name)
    except Exception as e:
        print(e)

    # if scp succeeded, rm the outstanding package
    if scp_success:
        emit_log(pkg_yaml, approved=True)
        print('Package successfully approved.')
        os.remove(config_yaml['outstanding_path']+pkgname)
    else:
        print('Not currently connected to deployment server.')

    # remove current .tar.gz from outstanding dir
    os.remove(config_yaml['tmp_path']+approval_name)

    # rm files in tmp/rollback dir before deleting
    rollback_file_list = glob.glob(config_yaml['tmp_path']+'rollback/*')
    for file in rollback_file_list:
        os.remove(file)
    # rm rollback dir in tmp before scrubbing tmp
    os.rmdir(config_yaml['tmp_path']+'rollback/')

    # removes all loose files in tmp dir (from the recent .tar.gz creation)
    tmp_file_list = glob.glob(config_yaml['tmp_path']+"*")
    for file in tmp_file_list:
        os.remove(file)


def setroot(root_path):
    '''
    Sets the root of the working project folder.
    Format:
        'pack setroot /home/Desktop/repo_name/'
    '''

    # validation attempt for ending slash,
    # comes into affect during directory traversal
    if '/' not in root_path[-1]:
        root_path = root_path + '/'

    # grab current config contents
    config_yaml = get_config()

    # puts root_path in if nonexistent, overwrites if existent
    config_yaml['root_path'] = root_path

    # dumps pack out to config file
    with open(config_path, 'w') as file:
        yaml.dump(config_yaml, file, sort_keys=False)


def log():
    '''Prints out info for last created packages. Format: 'pack log' '''

    config = get_config()
    if 'log_path' not in config:
        sys.exit("Hm, not seeing a log path inside your config.")

    with open(config['log_path'], 'r') as file:
        lines = file.readlines()

    # traverses list backwards to print logs last to first
    # only shows specified count
    # default show_last_logs = last 2 sent packages
    idx = -1
    count = 0
    last_delim = -1
    logcount = 0
    while count < len(lines):
        if '*-' in lines[idx]:
            subcount = idx
            while subcount <= last_delim:
                print(lines[subcount], end='')
                subcount = subcount + 1
            logcount = logcount + 1
            if logcount == show_last_logs:
                break
            last_delim = idx
        idx = idx - 1
        count = count + 1


def help():
    pass


if __name__ == '__main__':
    fire.Fire({
        'make': make,
        'install': install,
        'approve': approve,
        'packages': packages,
        'setroot': setroot,
        'log': log,
    })
