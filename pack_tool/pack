#!/usr/bin/python3
'''
Pack tool for making and sending
packages to deployment server

package naming convention: samplepak-1.0
'''
import fire
import socket
import os
import yaml
import sys
import subprocess
import tarfile
import shutil
import datetime
import glob

deploy_host = 'deploy'
deployment_server = f'{deploy_host}:/home/deploy/packages/incoming/'
config_path = os.environ['HOME'] + '/.config/packtool/config.yaml'
pkg_extension = '.tar.gz'
show_last_logs = 1


def get_config():
    '''grabs configuration info'''

    with open(config_path, 'r') as file:
        config_yaml = yaml.safe_load(file)

    return config_yaml


def emit_log(yaml_dict, make=False, install=False):
    '''Takes in dict of pkg information, writes to log file'''

    tagline = ''
    if make:
        tagline = 'Package Created'
    elif install:
        tagline = 'Package Installed'

    time = datetime.datetime.now().ctime()
    config_yaml = get_config()

    with open(config_yaml['log_path'], 'a') as file:
        file.write('*-\n')
        file.write(tagline + '\n')
        file.write(time + '\n')
        yaml.dump(yaml_dict, file, sort_keys=False)


def get_file_paths(args, root):
    '''gets full paths for given files'''

    # directory traversal to establish full paths for files
    installpaths = {}
    duplicate_check = {}
    for dir_name, sub_dir_list, file_list in os.walk(root):
        if '.git' not in dir_name:
            if 'pycache' not in dir_name:
                for fname in file_list:
                    if fname in args:
                        # dir slash issue correction due to os.walk subdirs
                        if '/' not in dir_name[-1]:
                            directory_name = dir_name+'/'
                        else:
                            directory_name = dir_name
                        # check for duplicate filenames spawning multiple paths
                        if fname not in installpaths:
                            installpaths[fname] = directory_name+fname
                        else:
                            if fname not in duplicate_check:
                                duplicate_check[fname] = [directory_name+fname]
                                duplicate_check[fname].append(installpaths[fname])
                            else:
                                duplicate_check[fname].append(directory_name+fname)

    # check if all given filenames have found their paths
    if len(installpaths) != len(args):
        sys.exit("Not all files found, check names")

    # duplicate checking
    if len(duplicate_check) >= 1:
        print('These paths were found with duplicate file names:')
        for key in duplicate_check:
            print(f'{key}:')
            for path in duplicate_check[key]:
                print(f'\t{duplicate_check[key].index(path)}: {path}')
            correct_path = 1000
            while correct_path not in range(0, len(duplicate_check[key])):
                correct_path = int(input('Choose correct path by number: '))
            installpaths[key] = duplicate_check[key][correct_path]

    return installpaths


def make(pkgname, *args):
    '''
    Creates and sends package. Format: 'pack make samplepak-1.2 file1 file2 file3'
    '''

    # ensure proper package name convention and parameter order (kindof)
    try:
        pkgversion = float(pkgname.split('-')[1])
    except Exception:
        sys.exit('Error: Double check your order or package naming convention')

    # get config yaml info and config path
    config_yaml = get_config()

    # user needs to set the root of their working project folder before proceeding
    if 'root_path' not in config_yaml:
        sys.exit('Run "pack setroot <full path>" to set the root of your project file directory then rerun')

    # get the full paths for the given files
    installpaths = get_file_paths(args, config_yaml['root_path'])

    # establish the yaml structure for the package
    yaml_dict = {'pkgid': '', 'pkgname': pkgname, 'pkgversion': str(pkgversion),
            'sourcenode': socket.gethostname(), 'pkgstatus': 'new',
            'install': installpaths}

    # write pkg.yaml to tmp for packaging
    with open(config_yaml['tmp_path'] + 'pkg.yaml', 'w') as file:
        yaml.dump(yaml_dict, file, sort_keys=False)

    # copy pkg files to tmp for packaging
    for fname in installpaths:
        shutil.copyfile(installpaths[fname], config_yaml['tmp_path']+fname)

    # tar.gz files in tmp, changing working directory to tmp
    subprocess.run(f'tar -czf {pkgname}{pkg_extension} *', cwd=config_yaml['tmp_path'], shell=True)

    # send pkg.tar.gz to deployment server
    #subprocess.run(['scp', config_yaml['tmp_path']+pkgname+pkg_extension, deployment_server])

    # remove all files in tmp, assuming ubuntu gio for now, not using rm * for safety
    #subprocess.run('gio trash *', cwd=config_yaml['tmp_path'], shell=True)
    #tmp_file_list = glob.glob(config_yaml['tmp_path']+"*")
    #for file in tmp_file_list:
    #    os.remove(file)

    # add package details to log
    emit_log(yaml_dict, make=True)


def unpack_yaml(pkg_path, tmp_path):
    '''takes in src path of tar.gz, writes pkg yaml to tmp, returns yaml'''

    # reading pkg.yaml inside package.tar.gz, stores to tmp dir (was easier this way)
    command = f"tar -xf {pkg_path} -C {tmp_path} pkg.yaml"
    os.system(command)
    pkg_yaml_path = tmp_path + 'pkg.yaml'
    with open(pkg_yaml_path, 'r') as file:
        pkg_yaml = yaml.safe_load(file)

    # clean file from tmp
    os.remove(pkg_yaml_path)

    return pkg_yaml


def unpack_tar_gz(pkg_path, tmp_path):
    '''unpacks tar to tmp to read pkg.yaml and install files'''

    # unpack tar.gx to tmp
    command = f"tar -xf {pkg_path} -C {tmp_path}"
    os.system(command)
    pkg_yaml_path = tmp_path + 'pkg.yaml'
    with open(pkg_yaml_path, 'r') as file:
        pkg_yaml = yaml.safe_load(file)

    return pkg_yaml


def repack_tar_gz(pkg_yaml):
    '''
    rewrites pkg.yaml with updated pkgstatus
    repacks tar in tmp, mvs to outstanding_packages, deletes original package
    '''

    config_yaml = get_config()
    tmp_path = config_yaml['tmp_path']
    outstanding_path = config_yaml['outstanding_path']

    pkgname = pkg_yaml['pkgname']
    pkg_extension = '.tar.gz'
    pkg_yaml['pkgstatus'] = 'outstanding'

    with open(tmp_path + 'pkg.yaml', 'w') as file:
        yaml.dump(pkg_yaml, file, sort_keys=False)

    # create new tar.gz from tmp files, change working dir to tmp then execute command
    subprocess.run(f'tar -czf {pkgname}{pkg_extension} *', cwd=tmp_path, shell=True)

    # move tar.gz to outstanding_packages
    shutil.move(tmp_path+pkgname+pkg_extension, outstanding_path)

    # remove original tar.gz from new_packages
    os.remove(config_yaml['new_pkg_path']+pkgname+pkg_extension)


def pack_backup(new_pkg_name, bak_tmp):
    '''
    tar.gz the current backup file from the last installation
    stored in tmp until backup dir is scrubbed
    '''
    pkg_ext = '.tar.gz'
    pkgname = f'backup_to_{new_pkg_name}'
    config_yaml = get_config()
    
    # tar.gz the files in bak_tmp
    subprocess.run(f'tar -czf {pkgname}{pkg_ext} *', cwd=bak_tmp, shell=True)
    
    #mv the tar.gz to backups
    shutil.move(bak_tmp+pkgname+pkg_ext, config_yaml['backup_path'])

def install(pkgname):
    '''
    Installs next package.
    Format:
        'pack install pkgname'
    '''
    ext = '.tar.gz'

    if ext not in pkgname:
        pkgname = pkgname+ext

    config_yaml = get_config()

    # should only be one file in directory
    file = os.listdir(config_yaml['new_pkg_path'])
    if not file:
        print('No packages to install.')
        return
    elif pkgname not in file[0]:
        print('Check package name.')
        return
    else:
        pkg_yaml = unpack_tar_gz(config_yaml['new_pkg_path']+file[0], config_yaml['tmp_path'])

    # grab install paths from new pkg yaml
    path_dict = pkg_yaml['install']

    # to store package/state reconstruction information
    updated_files = {}
    new_files = {}
    new_dirs_and_files = {}
    # if existing, copy file to backup directory, take note in yaml
    # if not existing but parent directories exist, take note in yaml
    # if not existing and parent directories not existing, take note in yaml

    # dynamically make backup tmp while creating backup package
    base_path = config_path[:config_path.index('config.yaml')]
    bak_tmp = base_path+'bak_tmp/'
    os.mkdir(bak_tmp)

    for key in path_dict:
        if os.path.isfile(path_dict[key]):
            shutil.copy(path_dict[key], bak_tmp)
            updated_files[key] = path_dict[key]
        elif os.path.isdir(path_dict[key][:path_dict[key].index(key)]):
            new_files[key] = path_dict[key]
        else:
            new_dirs_and_files[key] = path_dict[key]

    rollback_dict = {
            'updated_files': updated_files,
            'new_files': new_files,
            'new_dirs_and_files': new_dirs_and_files
    }

    # create paths in the case that new folders were created
    for key in path_dict:
        # slice off file at the end of file path, create path if nonexistent
        path = path_dict[key][:path_dict[key].index(key)]
        if not os.path.isdir(path):
            command = f'mkdir -p {path}'
            os.system(command)

    # copy files to given paths to install
    for key in path_dict:
        shutil.copy(config_yaml['tmp_path']+key, path_dict[key])

    # repacks installed pkg, moves to outstanding dir
    repack_tar_gz(pkg_yaml)

    # removes all loose files in tmp dir (from the installed pkg)
    tmp_file_list = glob.glob(config_yaml['tmp_path']+"*")
    for file in tmp_file_list:
        os.remove(file)

    # dump rollback yaml to file in bak_tmp
    with open(bak_tmp+'rollback.yaml', 'w') as file:
        yaml.dump(rollback_dict, file, sort_keys=False)

    # packs up backup files and rollback.yaml in bak_tmp
    # mvs the tar.gz to backups, embeds pkg installed name into backups name
    pack_backup(pkg_yaml['pkgname'], bak_tmp)

    # removes all loose files in bak_tmp
    bak_tmp_file_list = glob.glob(bak_tmp+"*")
    for file in bak_tmp_file_list:
        os.remove(file)

    # removes the bak_tmp directory
    os.rmdir(bak_tmp)

    pkg_yaml['details'] = rollback_dict
    emit_log(pkg_yaml, install=True)

    print('Package installed successfully. Check log for details.')


def packages():
    '''
    Lists next package ready to be installed.
    Format:
        'pack packages'
    '''
    config_yaml = get_config()

    # should only be one file in directory
    file = os.listdir(config_yaml['new_pkg_path'])
    if not file:
        print('No packages to install.')
        return
    else:
        pkg_yaml = unpack_yaml(config_yaml['new_pkg_path']+file[0], config_yaml['tmp_path'])

    t = os.path.getmtime(config_yaml['new_pkg_path']+file[0])
    date = datetime.datetime.fromtimestamp(t).ctime()

    print('*********************')
    print('1 Package to install:')
    print('*********************')
    print(f'***Filename: {file[0]}***')
    print(f'***Uploaded: {date}***')
    for key in pkg_yaml:
        if isinstance(pkg_yaml[key], dict):
            print(f'\t{key}:')
            for key2, value in pkg_yaml[key].items():
                print(f'\t  {key2}: {value}')
        else:
            print(f'\t{key}: {pkg_yaml[key]}')


def setroot(root_path):
    '''
    Sets the root of the working project folder.
    Format:
        'pack setroot /home/Desktop/repo_name/'
    '''

    # validation attempt for ending slash,
    # comes into affect during directory traversal
    if '/' not in root_path[-1]:
        root_path = root_path + '/'

    # grab current config contents
    config_yaml = get_config()

    # puts root_path in if nonexistent, overwrites if existent
    config_yaml['root_path'] = root_path

    # dumps pack out to config file
    with open(config_path, 'w') as file:
        yaml.dump(config_yaml, file, sort_keys=False)


def log():
    '''Prints out info for last created packages. Format: 'pack log' '''

    config = get_config()
    if 'log_path' not in config:
        sys.exit("Hm, not seeing a log path inside your config.")

    with open(config['log_path'], 'r') as file:
        lines = file.readlines()

    # traverses list backwards to print logs last to first
    # only shows specified count
    # default show_last_logs = last 2 sent packages
    idx = -1
    count = 0
    last_delim = -1
    logcount = 0
    while count < len(lines):
        if '*-' in lines[idx]:
            subcount = idx
            while subcount <= last_delim:
                print(lines[subcount], end='')
                subcount = subcount + 1
            logcount = logcount + 1
            if logcount == show_last_logs:
                break
            last_delim = idx
        idx = idx - 1
        count = count + 1


def help():
    pass


if __name__ == '__main__':
    fire.Fire({
        'make': make,
        'install': install,
        'packages': packages,
        'setroot': setroot,
        'log': log,
    })
